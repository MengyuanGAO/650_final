{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### countvectorizer vs. tfidfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = list(train_df.question_text)\n",
    "cvectorizer = CountVectorizer()\n",
    "XLc = cvectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lgc = LogisticRegression(C=1.0)\n",
    "lgc.fit(XLc, list(train_df.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvectorizer = TfidfVectorizer()\n",
    "XLt = tvectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgt = LogisticRegression(C=1.0)\n",
    "lgt.fit(XLt, list(train_df.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf logistic coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfeatures = tvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgt_scores = list(zip(tfeatures, lgt.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tscore_dict = dict(lgt_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### countvectorizer logistic coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfeatures = cvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgc_scores = list(zip(cfeatures, lgc.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cscore_dict = dict(lgc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scoring difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_words(vect_method='tfidf', query='Has the United States become the largest dictatorship in the world?'):\n",
    "    # preprocessing\n",
    "    from nltk import word_tokenize\n",
    "    tokens = word_tokenize(query.lower())\n",
    "    print(tokens)\n",
    "    \n",
    "    if vect_method == 'tfidf':\n",
    "        b = tscore_dict\n",
    "    else:\n",
    "        b = cscore_dict\n",
    "        \n",
    "    scores = [b[t] if (t in b) and (t not in stopwords) else 0 for t in tokens]\n",
    "    \n",
    "    print(scores)\n",
    "\n",
    "    import numpy as np\n",
    "    arr = np.array(scores)\n",
    "    indices = [s for s in arr.argsort()[-5:][::-1] if s > 1.0]\n",
    "    # uncomment the following to change \n",
    "#     print(scores)\n",
    "#     indices = [scores.index(ii) for ii in scores if (ii >= 1.0) and (tokens[scores.index(ii)] not in stopwords)]\n",
    "    \n",
    "    words = list(set([tokens[i] for i in indices]))\n",
    "    print(words)\n",
    "\n",
    "    ans = []\n",
    "    for ind, ii in enumerate(query.lower().split()):\n",
    "        for jj in words:\n",
    "            if jj in ii and len(ii) - len(jj) <= 1:\n",
    "                ans.append(ind)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['why', 'do', \"n't\", 'poor', 'countries', 'print', 'more', 'money', 'to', 'use', 'for', 'paying', 'for', 'education', ',', 'etc', '.', '?']\n",
      "[0, 0, 0, 1.9050414062898482, 0.08918326712227044, -0.90463146657921123, 0, 0.75202372081650515, 0, -0.40337277627113183, 0, 0.66426794313579152, 0, -0.072099506105499991, 0, 1.2447212208436367, 0, 0]\n",
      "['money', 'etc', 'paying', 'countries', 'poor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 3, 6, 10]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_words(vect_method='tfidf', query=\"Why don't poor countries print more money to use for paying for education, etc.?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['why', 'do', \"n't\", 'poor', 'countries', 'print', 'more', 'money', 'to', 'use', 'for', 'paying', 'for', 'education', ',', 'etc', '.', '?']\n",
      "[0, 0, 0, 0.64791479878555613, -0.044814572523616994, -0.44811434626675867, 0, 0.24047668307504766, 0, -0.076402267102584034, 0, 0.21851726703762406, 0, -0.023666621953956558, 0, -0.39314092549589297, 0, 0]\n",
      "['money', 'paying', '.', 'poor', '?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 6, 10]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_words(vect_method='count', query=\"Why don't poor countries print more money to use for paying for education, etc.?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['why', 'do', \"n't\", 'usa', 'citizens', 'realize', 'that', 'trump', 'is', 'rapidly', 'doing', 'what', 'terrorists', 'could', 'not', ',', 'i.e.', ',', 'push', 'the', 'country', 'towards', 'irrevocable', 'catastrophe', '?']\n",
      "[0, 0, 0, 1.9629288282951698, 2.2265968115514649, 3.2391450545783962, 0, 5.694714780064527, 0, 0.4230896111986327, 0, 0, 4.0264540375332336, -0.67789223151347455, 0, 0, 0, 0, 0.88831637999819757, 0, 1.2667648593983192, 0.85720849626362028, 0.03976211550709665, -0.15962684893709167, 0]\n",
      "['citizens', 'usa', 'trump', 'realize', 'terrorists']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 6, 11]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_words(vect_method='tfidf', query=\"Why don't USA citizens realize that Trump is rapidly doing what terrorists could not, i.e., push the country towards irrevocable catastrophe?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['why', 'do', \"n't\", 'usa', 'citizens', 'realize', 'that', 'trump', 'is', 'rapidly', 'doing', 'what', 'terrorists', 'could', 'not', ',', 'i.e.', ',', 'push', 'the', 'country', 'towards', 'irrevocable', 'catastrophe', '?']\n",
      "[0, 0, 0, 0.61731510387052568, 0.64162569671886782, 0.97711021199434023, 0, 1.4349582961003773, 0, 0.24509268053202549, 0, 0, 1.5607103828349602, -0.11215263541423476, 0, 0, 0, 0, 0.2323969184874197, 0, 0.3755065649627764, -0.036098490919582615, -0.01900937913138941, -0.29710712730296779, 0]\n",
      "['citizens', 'usa', 'trump', 'realize', 'terrorists']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 6, 11]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_words(vect_method='count', query=\"Why don't USA citizens realize that Trump is rapidly doing what terrorists could not, i.e., push the country towards irrevocable catastrophe?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'can', 'you', 'tell', 'the', 'difference', 'between', 'a', 'russian', 'internet', 'troll', 'and', 'an', 'american', 'one', '?']\n",
      "[0, 0, 0, -0.091157046460830088, 0, -1.0831477290627616, 0, 0, 2.8571626483781083, -0.21569446989575794, 3.6278528915119521, 0, 0, 2.7549586725459432, -0.3507462133621001, 0]\n",
      "['an', 'troll', 'russian', 'american', '?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 8, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_words(vect_method='tfidf', query=\"How can you tell the difference between a Russian Internet troll and an American one?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'can', 'you', 'tell', 'the', 'difference', 'between', 'a', 'russian', 'internet', 'troll', 'and', 'an', 'american', 'one', '?']\n",
      "[0, 0, 0, -0.061350640038029175, 0, -0.29270115514699058, 0, 0, 0.88018751839839993, -0.051015757369231488, 1.2272879540297057, 0, 0, 0.72268028338740065, -0.051562626526923325, 0]\n",
      "['an', 'troll', 'russian', 'american', '?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 8, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_words(vect_method='count', query=\"How can you tell the difference between a Russian Internet troll and an American one?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
